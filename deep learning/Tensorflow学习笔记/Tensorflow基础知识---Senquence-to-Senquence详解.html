<!DOCTYPE HTML>
<html>
<head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <title>Tensorflow基础知识---Senquence-to-Senquence详解 - sthsf's personal knowledge wiki</title>
    <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
    <meta name="description" content="A wiki website of sthsf when I learned new knowledgy and technics."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width" />

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)']]}
        });
        </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-78529611-1', 'auto');
        ga('send', 'pageview');

    </script>
</head>

<body>
<div id="container">
    
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#deep learning">deep learning</a>&nbsp;»&nbsp;<a href="/wiki/#deep learning-Tensorflow学习笔记">Tensorflow学习笔记</a>&nbsp;»&nbsp;Tensorflow基础知识---Senquence-to-Senquence详解</div>
</div>
<div class="clearfix"></div>
<div id="title">Tensorflow基础知识---Senquence-to-Senquence详解</div>
<div id="content">
  <h1 id="_1">写在前面</h1>
<p>Seq2Seq是基于tensorflow的一种通用编码器&amp;解码器框架，可用于机器翻译，文本摘要，会话模型，图像描述等。</p>
<h1 id="sequence_to_sequence-model">Sequence_to_Sequence Model</h1>
<p>常见的语言模型的研究对象是单一序列，例如（文本生成），而Sequence_to_Sequence Model同时研究两个序列之间的关系。Encoder-Decoder的基本结构如下：<br />
<img src="/wiki/static/images/seq2seq/Encoder-Decoder基本结构.jpg" alt="Encoder-Decoder基本结构"/><br />
表示sequence ABC被翻译成sequence WXYZ， 其中<EOS>是一句话的结束符。</p>
<p>上图是一个已经在时间维度上展开的Encoder-Decoder模型，典型的Sequence_to_Sequence Model通常是由两个RNN网络构成，一个被称为编码器，另一个被称为译码器，encoder负责把variable-length的序列编码成一个固定大小的语义表示向量(fixed-length vector representation)，我们可以理解为把一段文本进行语义表示。decoder则负责把encoder得到的fixed-length的语义向量解码成另一个variable-length的token序列，这个token序列就是另一个sequence，并且每个时刻t输出词的概率都与前t-1时刻的输出有关。优化时采用极大似然估计，让encoder前的序列A被encoder后在decoder得到的序列B的概率最大。在这里序列A和B的长度是可以不一样的。</p>
<p>我们将上面的模型展开可以得到：<br />
<center><img src="/wiki/static/images/seq2seq/encoder-decoder.png" alt="Encoder-Decoder展开"/></center></p>
<h2 id="encoder">Encoder</h2>
<p>Encoder的过程比较简单，一般直接用RNN(LSTM,GRU,RNN等)进行语义向量的生成，上图中每个圆圈代表一个RNNCell，每个time_step，我们能向Encoder中输入一个字/词（一般是表示这个字/词的一个实数向量），直到输入这个句子的最后一个字/词$(X_T)$,然后输出整个句子的语义向量c(一般的，$(c=h_{X_T})$，$(X_T)$是最后一个输入)。</p>
<p>因为RNN的特点就是把前面每一步输入信息都考虑进来了，所以理论上这个c就能够包含整个句子的信息。因此，c可以作为这个句子的一种语义表示。即为该句的句向量。<br />
$$<br />
h_t = f(x_t, h_{t-1})<br />
$$<br />
$$<br />
c = \phi(h_1,h_2,...,h_T)<br />
$$<br />
其中f是非线性激活函数，可以是sigmod、tan、relu、lstm等，$(h_{t-1})$是上一个隐节点输出，$(x_t)$是当前时刻的输入，向量c通常为RNN的最后一个隐节点（h,Hidden state）,或者是多个隐节点的加权和。</p>
<h2 id="decoder">Decoder</h2>
<p>在Decoder过程中，就是一步步将句向量c中蕴含的信息分析出来。编码完成后，我们的语义向量c会进入一个RNN解码器中进行解释，简单说，解释的过程就是被理解为运用贪心算法（一种局部最优解算法，即选取一种度量标准，默认在当前状态下进行最好的选择）来返回对应概率最大的词汇，或是通过集束搜索（Beam Search，一种启发式搜索算法，可以基于设别性能给予时间允许内的最优解）在序列输出检索大量的词汇，从而得到最优选择。</p>
<p>该模型的decoder过程是使用另一个RNN通过当前状态$(h_t)$来预测当前的输出符号$(y_t)$, 其中的$(h_t)$,$(y_t)$都与其前一个隐状态和输出有关：<br />
$$<br />
s_t= f(s_{t-1}, y_{t-1}, c)<br />
$$<br />
同样，根据$(s_t)$我们就可以求出$(y_t)$的条件概率<br />
$$<br />
P(y_t|y_{t-1},...,y_1,c)=g(s_t, y_{t-1}, c)<br />
$$<br />
这里有两个函数$(f)$和$(g)$，一般来说，f函数结构应该是一个RNNCell结构或者类似的结构；g函数一般是softmax。我们可以这样理解，在Encoder中我们得到一个涵盖整个句子信息的实数向量c，现在我们一步步从c中抽取信息。<br />
首先给Decoder一个启动信号$(y_0)$(如特殊符号<START>),然后Decoder根据$(s_0,y_0,c)$就能够计算出$(y_1)$的概率分布了，同理，根据$(s_1, y_1, c)$可以计算$(y_2)$的概率分布，依此类推直到预测到结束的特殊标志<END>,才结束预测。<br />
<a href="https://github.com/nicolas-ivanov/tf_seq2seq_chatbot">github</a>上有一张更详细的图：<br />
<center><img src="/wiki/static/images/seq2seq/encoder-decoder展开.png" alt="Encoder-Decoder详细展开"/></center></p>
<p>上图展示的是一个邮件对话的应用场景，图中的 Encoder 和 Decoder 都只展示了一层的普通的 LSTMCell。从上面的结构中，我们可以看到，整个模型结构还是非常简单的。 EncoderCell 最后一个时刻的状态 $([c_{X_T},h_{X_T}])$ 就是上面说的中间语义向量 c ，它将作为 DecoderCell 的初始状态。然后在 DecoderCell 中，每个时刻的输出将会作为下一个时刻的输入。以此类推，直到 DecoderCell 某个时刻预测输出特殊符号 <END> 结束。</p>
<p>在原论文中，作者使用的是4层LSTM，原理上跟1层LSTM是一样的，<a href="http://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture1.pdf">CS224n</a>中给我们提供了一个三层的模型结构有助于我们对Encode-Decode的理解：<br />
<center><img src="/wiki/static/images/seq2seq/4-level-encode-decode.jpg" alt="Encoder-Decoder-4层展开"/></center></p>
<h2 id="attention-mechanism">Attention Mechanism</h2>
<p>当Encode的序列过长时，会导致c保留的信息缺失，<a href="https://arxiv.org/pdf/1409.0473.pdf">Bahdanau</a>在Encoder和Decoder的基础上提出了注意力机制，<br />
注意力机制模型主要的修改在decoder过程，传统的decoder中，每次预测下个词都会用到语义向量词c，而传统的decoder中的c主要是最后一个时刻的隐藏状态，这就意味着不管decoder生成的哪个单词，句子X中的任意单词对生成某个目标单词$(y_i)$的影响是相同的，也就是说没有加入注意力机制模型的encoder-decoder模型，目标序列对预测序列的贡献是相同的，例如，在翻译模型当中，每个被翻译目标单词对与翻译目标单词的贡献显然是不同的，<br />
而传统的encoder-decoder模型无法体现这一点，这就是为何说它没有引入注意力机制的原因。没有引入注意力机制的模型在输入句子比较短的时候估计问题不大，但是如果输入句子比较长，此时所有语义完全通过一个中间语义向量来表示，单词自身的信息已经消失，可想而知会丢失很多细节信息，这也是为何要引入注意力模型的重要原因。</p>
<p>而注意力机制在decoder预测的时候，将encoder中每个时刻的隐藏状态都利用上了，这样，encoder过程中的多个语义信息(隐藏状态)就可以都被利用来表达整个句子的信息了。增加了注意力机制模型的encoder-decoder框架理解起来如下图所示：<br />
<center><img src="/wiki/static/images/seq2seq/am-encoder-decoder.jpg" alt="attention mechanism模型理解"/></center><br />
其中，每个&amp;(c_i)&amp;可能对应着不同的源语句子单词的注意力分配概率分布.</p>
<p>另外，在encoder的过程中还使用了双向循环网络(bidirection RNN)，这比单向的效果要好。模型结构见下图：<br />
<center><img src="/wiki/static/images/seq2seq/attention mechanism.png" alt="attention mechanism模型结构"/></center><br />
如上图所示, 在注意机制中，我们的源序列&amp;(x=(x_1, x_2, ...., x_t))&amp;分别被正向和反向地输入模型，进而得到了正反两层隐节点，语义向量c则由RNN中的隐节点h通过不同权重a加权而成，其公式如下：<br />
$$<br />
c_t=\sum_{j=1}^{T_x}{\alpha_{tj}h_{j}};\ <br />
\alpha_{tj} = \frac{e^{\eta(s_{t-1},h_j)}}{\sum_{j'}e^{\eta(s_{t-1},h_{j'})}}<br />
$$<br />
其中，&amp;(\eta)&amp;为一个调整“注意回应强度”的函数。我们知道每一个隐节点&amp;(h_i)&amp;都包含了对应的输入字符&amp;(x_i)&amp;以及其对上下文的联系，这么做意义就在于现在模型可以突破固定长度输入的限制，根据不同的输入长度构建不同个数的隐节点，故不论我们输入的序列（比如待翻译的一段原文）长度如何，都可以得到模型输出结果。</p>
<h1 id="tensorflowseq2seq">Tensorflow中的Seq2Seq</h1>
<h1 id="_2">应用领域</h1>
<ul>
<li>机器翻译</li>
<li>智能对话和问答</li>
<li>
<p>自动编码与分类器训练</p>
<p>2015年，Google的Andrew M.Dai和Quo V.Le提出了将Seq2Seq的自动编码器作为LSTM文本分类的一个预训练步骤，从而提高了分类的稳定性。这使得Seq2Seq技术的目的不再局限于得到序列本身，为其应用领域翻开了崭新的一页。</p>
</li>
</ul>
<h1 id="_3">参考文献</h1>
<p><a href="https://www.oschina.net/p/seq2seq">通用编码器&amp;解码器框架seq2seq</a></p>
<p><a href="http://blog.csdn.net/jerr__y/article/details/53749693">seq2seq学习笔记</a></p>
<p><a href="http://www.jianshu.com/p/124b777e0c55">Seq2Seq的DIY简介</a></p>
<p><a href="https://github.com/jxieeducation/DIY-Data-Science/blob/master/research/seq2seq.md">The DIY Guide to Seq2Seq</a></p>
<p><a href="http://www.kemaswill.com/about/">Junwei Pan's Blog</a></p>
<p><a href="http://blog.csdn.net/diligent_321/article/details/53590289">TensorFlow中Sequence-to-Sequence样例代码详解</a></p>
<p><a href="http://blog.csdn.net/appleml/article/details/54017873">sequence_loss_by_example(logits, targets, weights)</a></p>
<p><a href="http://blog.csdn.net/u012871493/article/details/72350332">tensorflow的legacy_seq2seq模块</a></p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/legacy_seq2seq/sequence_loss_by_example">tf.contrib.legacy_seq2seq.sequence_loss_by_example</a></p>
<p><a href="http://www.2cto.com/kf/201611/561130.html">tensorflow学习笔记（十一）：seq2seq Model</a></p>
<p><a href="http://blog.csdn.net/u012436149/article/details/52976413">tensorflow学习笔记（十一）：seq2seq Model相关接口介绍</a></p>
<p><a href="http://www.360doc.com/content/17/0321/10/10408243_638692790.shtml">RNN回归例子</a></p>
<p><a href="https://r2rt.com/styles-of-truncated-backpropagation.html">Styles of Truncated Backpropagation</a></p>
<p><a href="http://www.360doc.com/content/17/0321/10/10408243_638692495.shtml">lstm分类的例子涉及dynamic_nn</a></p>
<p><a href="http://blog.csdn.net/u010223750/article/details/71079036">tensorflow高阶教程:tf.dynamic_rnn</a></p>
<p><a href="http://blog.csdn.net/u014595019/article/details/52759104"> tensorflow笔记：多层LSTM代码分析</a></p>
<p><a href="http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/">RNNs in Tensorflow, a Practical Guide and Undocumented Features</a></p>
<p><a href="http://blog.csdn.net/mydear_11000/article/details/52440115">解析Tensorflow官方PTB模型的demo</a></p>
<p><a href="http://blog.csdn.net/u012436149/article/details/52828786">tensorflow0.10.0 ptb_word_lm.py 源码解析</a></p>
<p><a href="http://blog.csdn.net/u012436149/article/details/53843158"> tensorflow学习笔记（二十六）：构建TF代码</a></p>
<p><a href="http://blog.csdn.net/u012436149/article/details/52874718">tensorflow学习笔记（三）：损失函数</a></p>
</div>
<div id="content-footer">created in <span class="create-date date"> 2017-07-06 00:00 </span></div>
<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  title: 'Tensorflow基础知识---Senquence-to-Senquence详解',
  owner: 'sthsf',
  repo: 'wiki',
  oauth: {
    client_id: '086c54c5fd95adfdc372',
    client_secret: '2ad9ebe87b952d2c77fccf99c334881b91eaa73d',
  },
  // ...
  // For more available options, check out the documentation below
})
gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

</div>
<div id="footer">
            <span>
                Copyright © 2017 sthsf.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
                Fork me in <a href="https://github.com/sthsf/wiki" target="_blank"> github </a>.
            </span>
</div>


<!--百度统计-->
<script>
    var _hmt = _hmt || [];
    (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?90e1dcdd1938573c19f9ff6521188e91";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>


</body>
</html>