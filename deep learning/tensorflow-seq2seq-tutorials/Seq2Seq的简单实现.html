<!DOCTYPE HTML>
<html>
<head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <title>Seq2Seq的简单实现 - sthsf's personal knowledge wiki</title>
    <meta name="keywords" content="technology, machine learning, data mining, economics, accounting"/>
    <meta name="description" content="A wiki website of sthsf when I learned new knowledgy and technics."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width" />

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)']]}
        });
        </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-78529611-1', 'auto');
        ga('send', 'pageview');

    </script>
</head>

<body>
<div id="container">
    
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#deep learning">deep learning</a>&nbsp;»&nbsp;<a href="/wiki/#deep learning-tensorflow-seq2seq-tutorials">tensorflow-seq2seq-tutorials</a>&nbsp;»&nbsp;Seq2Seq的简单实现</div>
</div>
<div class="clearfix"></div>
<div id="title">Seq2Seq的简单实现</div>
<div id="content">
  <h1 id="_1">写在前面</h1>
<p>在<a href="">Tensorflow基础知识---Senquence-to-Senquence详解</a>一文中详细讲述了sequence-to-sequence的原理，本文主要是基于前文中的讲述内容，使用tensorflow实现出来，便于对原理的理解。<br />
本文主要参考<a href="https://github.com/ematvey/tensorflow-seq2seq-tutorials">ematvey</a>在github上的代码。</p>
<h1 id="simple-seq2seq-model-with-dynamic-unrolling">simple seq2seq model with dynamic unrolling</h1>
<p>本文实现的是一个最简单的seq2seq模型，即只包含前向传播的编码过程，和没有注意力机制的解码过程。并且没有使用<code>tf.contrib.seq2seq</code>接口。本代码主要的结构是参考的是 Sutskever, Vinyals and Le (2014)中提到的encoder-decoder结构。</p>
<p>具体描述参见<a href="">Tensorflow基础知识---Senquence-to-Senquence详解</a>图一的详细解释。</p>
<h1 id="_2">代码详解</h1>
<div class="hlcode"><pre><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">tensorflow</span> <span class="n">as</span> <span class="n">tf</span>
</pre></div>


<h2 id="_3">数据预处理</h2>
<div class="hlcode"><pre><span class="cp"># 填充标记</span>
<span class="n">PAD</span> <span class="o">=</span> <span class="mi">0</span>
<span class="cp"># 结束标记</span>
<span class="n">EOS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="cp"># 词汇量的大小</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="cp"># 输入数据的词嵌套的大小</span>
<span class="n">input_embedding_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="cp"># 编码中RNN的隐藏单元的个数</span>
<span class="n">encoder_hidden_units</span> <span class="o">=</span> <span class="mi">25</span>
<span class="cp"># 解码中RNN的隐藏单元的个数</span>
<span class="n">decoder_hidden_units</span> <span class="o">=</span> <span class="n">encoder_hidden_units</span>
</pre></div>


<p>定义编码输入，解码输入和输出</p>
<div class="hlcode"><pre><span class="cp"># encoder_inputs:[max_time, batch_size]</span>
<span class="n">encoder_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">None</span><span class="p">,</span> <span class="n">None</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="err">&#39;</span><span class="n">encoder_inputs</span><span class="err">&#39;</span><span class="p">)</span>
<span class="cp"># decoder_targets: [max_time, batch_size]</span>
<span class="n">decoder_targets</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">None</span><span class="p">,</span> <span class="n">None</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="err">&#39;</span><span class="n">decoder_targets</span><span class="err">&#39;</span><span class="p">)</span>
<span class="cp"># decoder_inputs: [max_time, batch_size]</span>
<span class="cp"># 实际上是不用手动feeddecoder_inputs的，</span>
<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">None</span><span class="p">,</span> <span class="n">None</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="err">&#39;</span><span class="n">decoder_inputs</span><span class="err">&#39;</span><span class="p">)</span>
</pre></div>


<p>对输入数据进行embedding操作</p>
<div class="hlcode"><pre><span class="n">embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">input_embedding_size</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="cp"># encoder_inputs_embeded: [max_time, batch_size, input_embedding_size]</span>
<span class="n">encoder_inputs_embeded</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">encoder_inputs</span><span class="p">)</span>
<span class="cp"># decoder_inputs_embeded: [max_time, batch_size, input_embedding_size]</span>
<span class="n">decoder_inputs_embeded</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">)</span>
<span class="n">decoder_inputs_embeded</span>
</pre></div>


<h2 id="encoder">Encoder过程</h2>
<div class="hlcode"><pre><span class="cp"># 定义编码RNNCell</span>
<span class="n">encoder_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">rnn</span><span class="p">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">encoder_hidden_units</span><span class="p">)</span>
<span class="cp"># dynamic RNN在改变batch_size或者sequence_length的时候是不需要重新训练的，但是如果改变了vocabulary size的时候是需要重新训练模型的</span>
<span class="cp"># time_major=True表示batch_size在第二列，即encoder_inputs_embeded的结构为[max_time, batch_size, embedding_dim]</span>
<span class="cp"># 如果time_major=True则表示batch_size在第二列，即encoder_inputs_embeded的机构为[batch_size, max_time, embedding]</span>
<span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">encoder_cell</span><span class="p">,</span>
                                                         <span class="n">encoder_inputs_embeded</span><span class="p">,</span>
                                                         <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">time_major</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>
<span class="cp"># decoder过程中不需要encoder的输出，所以将其删除，仅保留运行输出的隐藏状态</span>
<span class="n">del</span> <span class="n">encoder_outputs</span>
</pre></div>


<h2 id="decoder">Decoder过程</h2>
<div class="hlcode"><pre><span class="cp"># 定义解码RNNCell</span>
<span class="n">decoder_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">rnn</span><span class="p">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">decoder_hidden_units</span><span class="p">)</span>
<span class="cp"># </span>
<span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">decoder_final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">decoder_cell</span><span class="p">,</span> 
                                                         <span class="n">decoder_inputs_embeded</span><span class="p">,</span>
                                                         <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_final_state</span><span class="p">,</span>
                                                         <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">time_major</span><span class="o">=</span><span class="n">True</span><span class="p">,</span><span class="n">scope</span><span class="o">=</span><span class="err">&#39;</span><span class="n">plain_decoder</span><span class="err">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div id="content-footer">created in <span class="create-date date"> 2017-08-02 00:00 </span></div>
<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  title: 'Seq2Seq的简单实现',
  owner: 'sthsf',
  repo: 'wiki',
  oauth: {
    client_id: '086c54c5fd95adfdc372',
    client_secret: '2ad9ebe87b952d2c77fccf99c334881b91eaa73d',
  },
  // ...
  // For more available options, check out the documentation below
})
gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

</div>
<div id="footer">
            <span>
                Copyright © 2017 sthsf.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
                Fork me in <a href="https://github.com/sthsf/wiki" target="_blank"> github </a>.
            </span>
</div>


<!--百度统计-->
<script>
    var _hmt = _hmt || [];
    (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?90e1dcdd1938573c19f9ff6521188e91";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>


</body>
</html>