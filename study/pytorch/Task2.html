<!DOCTYPE HTML>
<html>
<head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <title>Getting Started - LiYu's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Economics"/>
    <meta name="description" content="A wiki website of sthsf when I learned new knowledgy and technics."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width" />

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)']]}
        });
        </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-78529611-1', 'auto');
        ga('send', 'pageview');

    </script>
</head>

<body>
<div id="container">
    
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#study">study</a>&nbsp;»&nbsp;<a href="/wiki/#study-pytorch">pytorch</a>&nbsp;»&nbsp;Getting Started</div>
</div>
<div class="clearfix"></div>
<div id="title">Getting Started</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">写在前面</a><ul>
<li><a href="#sigmoid">sigmoid函数</a></li>
<li><a href="#softmax">softmax函数</a></li>
<li><a href="#cross_entropy">cross_Entropy函数</a></li>
<li><a href="#_2">任务描述</a></li>
<li><a href="#_3">完整代码</a></li>
</ul>
</li>
<li><a href="#_4">参考文献</a></li>
</ul>
</div>
<h1 id="_1">写在前面</h1>
<p>1.numpy和pytorch实现梯度下降法<br />
2.设定初始值<br />
3.求取梯度<br />
4.在梯度方向上进行参数的更新<br />
5.numpy和pytorch实现线性回归<br />
6.pytorch实现一个简单的神经网络</p>
<p>导入的包</p>
<div class="hlcode"><pre><span class="n">import</span> <span class="n">os</span>
<span class="n">import</span> <span class="n">torch</span>
<span class="n">import</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span> <span class="n">as</span> <span class="n">nn</span>
<span class="n">import</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span> <span class="n">as</span> <span class="n">Data</span>
<span class="n">import</span> <span class="n">torchvision</span>
</pre></div>


<p>读取数据</p>
<div class="hlcode"><pre><span class="n">EPOCH</span> <span class="o">=</span> <span class="mi">1</span>  <span class="err">#</span> <span class="n">train</span> <span class="n">the</span> <span class="n">training</span> <span class="n">data</span> <span class="n">n</span> <span class="n">times</span><span class="p">,</span> <span class="n">to</span> <span class="n">save</span> <span class="n">time</span><span class="p">,</span> <span class="n">we</span> <span class="n">just</span> <span class="n">train</span> <span class="mi">1</span> <span class="n">epoch</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">DOWNLOAD_MNIST</span> <span class="o">=</span> <span class="n">False</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="cp"># Mnist digits dataset</span>
<span class="k">if</span> <span class="n">not</span> <span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="err">&#39;</span><span class="p">.</span><span class="o">/</span><span class="n">mnist</span><span class="o">/</span><span class="err">&#39;</span><span class="p">))</span> <span class="n">or</span> <span class="n">not</span> <span class="n">os</span><span class="p">.</span><span class="n">listdir</span><span class="p">(</span><span class="err">&#39;</span><span class="p">.</span><span class="o">/</span><span class="n">mnist</span><span class="o">/</span><span class="err">&#39;</span><span class="p">)</span><span class="o">:</span>
    <span class="err">#</span> <span class="n">not</span> <span class="n">mnist</span> <span class="n">dir</span> <span class="n">or</span> <span class="n">mnist</span> <span class="n">is</span> <span class="n">empyt</span> <span class="n">dir</span>
    <span class="n">DOWNLOAD_MNIST</span> <span class="o">=</span> <span class="n">True</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="err">&#39;</span><span class="p">.</span><span class="o">/</span><span class="n">mnist</span><span class="o">/</span><span class="err">&#39;</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>  <span class="err">#</span> <span class="n">this</span> <span class="n">is</span> <span class="n">training</span> <span class="n">data</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">download</span><span class="o">=</span><span class="n">DOWNLOAD_MNIST</span><span class="p">,</span>
<span class="p">)</span>

<span class="cp"># Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">Data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>  <span class="err">#</span> <span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>
</pre></div>


<h2 id="sigmoid">sigmoid函数</h2>
<p>sigmoid函数，将数据R映射到（0,1）区间上了。</p>
<h2 id="softmax">softmax函数</h2>
<p>softmax是将根据n个数值的大小来分配概率区间</p>
<p>一般来说，为了避免数值越界的话，会要求减去最大值。</p>
<p>但是这里我们是用logistic regression，数值都会在0，1区间中，不会太大，因此不用担心这个问题。</p>
<h2 id="cross_entropy">cross_Entropy函数</h2>
<p>cross_Entropy 就是交叉熵。</p>
<p>这里，一旦我们给出了标准的label之后，我们就知道实际的p值分布为</p>
<p>只有一个元素为1，其他元素为0的概率分布了。</p>
<p>也就是对应label的概率越大越好~</p>
<h2 id="_2">任务描述</h2>
<p>采用SDG，和DG算法</p>
<p>本文采用了pytorch实现，主要是为了避免手动算梯度。pytorch有autograd的机制。</p>
<p>本文一直采用的是固定步长<br />
- 实现SDG的部分代码<br />
从logistics regression模型中获取了</p>
<div class="hlcode"><pre><span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="n">logits</span><span class="p">.</span><span class="n">parameters</span><span class="p">()]</span>
<span class="n">A</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">b</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>


<p>通过查看pytorch的源码实现中关于优化器部分的实现，手动设置了梯度归零的操作，不然就会是累积梯度了。</p>
<div class="hlcode"><pre><span class="k">if</span> <span class="n">A</span><span class="p">.</span><span class="n">grad</span> <span class="n">is</span> <span class="n">not</span> <span class="n">None</span><span class="o">:</span>
    <span class="n">A</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>
    <span class="n">b</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>


<ul>
<li>梯度下降更新梯度</li>
</ul>
<div class="hlcode"><pre><span class="n">A</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">A</span><span class="p">.</span><span class="n">data</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">A</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span>
<span class="n">b</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="n">data</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">b</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span>
</pre></div>


<h2 id="_3">完整代码</h2>
<div class="hlcode"><pre><span class="n">import</span> <span class="n">os</span>

<span class="n">import</span> <span class="n">torch</span>
<span class="n">import</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span> <span class="n">as</span> <span class="n">nn</span>
<span class="n">import</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span> <span class="n">as</span> <span class="n">Data</span>
<span class="n">import</span> <span class="n">torchvision</span>
<span class="n">import</span> <span class="n">matplotlib</span><span class="p">.</span><span class="n">pyplot</span> <span class="n">as</span> <span class="n">plt</span>
<span class="n">EPOCH</span> <span class="o">=</span> <span class="mi">5</span>  <span class="err">#</span> <span class="n">train</span> <span class="n">the</span> <span class="n">training</span> <span class="n">data</span> <span class="n">n</span> <span class="n">times</span><span class="p">,</span> <span class="n">to</span> <span class="n">save</span> <span class="n">time</span><span class="p">,</span> <span class="n">we</span> <span class="n">just</span> <span class="n">train</span> <span class="mi">1</span> <span class="n">epoch</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">DOWNLOAD_MNIST</span> <span class="o">=</span> <span class="n">False</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="cp"># Mnist digits dataset</span>
<span class="k">if</span> <span class="n">not</span> <span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="err">&#39;</span><span class="p">.</span><span class="o">/</span><span class="n">mnist</span><span class="o">/</span><span class="err">&#39;</span><span class="p">))</span> <span class="n">or</span> <span class="n">not</span> <span class="n">os</span><span class="p">.</span><span class="n">listdir</span><span class="p">(</span><span class="err">&#39;</span><span class="p">.</span><span class="o">/</span><span class="n">mnist</span><span class="o">/</span><span class="err">&#39;</span><span class="p">)</span><span class="o">:</span>
    <span class="err">#</span> <span class="n">not</span> <span class="n">mnist</span> <span class="n">dir</span> <span class="n">or</span> <span class="n">mnist</span> <span class="n">is</span> <span class="n">empyt</span> <span class="n">dir</span>
    <span class="n">DOWNLOAD_MNIST</span> <span class="o">=</span> <span class="n">True</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="err">&#39;</span><span class="p">.</span><span class="o">/</span><span class="n">mnist</span><span class="o">/</span><span class="err">&#39;</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>  <span class="err">#</span> <span class="n">this</span> <span class="n">is</span> <span class="n">training</span> <span class="n">data</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">download</span><span class="o">=</span><span class="n">DOWNLOAD_MNIST</span><span class="p">,</span>
<span class="p">)</span>

<span class="cp"># Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">Data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>


<span class="n">class</span> <span class="n">Logits</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span><span class="o">:</span>
    <span class="n">def</span> <span class="n">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>
        <span class="n">super</span><span class="p">(</span><span class="n">Logits</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">def</span> <span class="n">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="n">test_data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="err">&#39;</span><span class="p">.</span><span class="o">/</span><span class="n">mnist</span><span class="o">/</span><span class="err">&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">False</span><span class="p">)</span>
<span class="n">test_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">test_data</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">type</span><span class="p">(</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">).</span><span class="n">cuda</span><span class="p">()</span> <span class="o">/</span> <span class="mf">255.</span>  <span class="err">#</span> <span class="n">shape</span> <span class="n">from</span> <span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span> <span class="n">to</span> <span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">value</span> <span class="n">in</span> <span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">.</span><span class="n">test_labels</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="n">logits</span> <span class="o">=</span> <span class="n">Logits</span><span class="p">().</span><span class="n">cuda</span><span class="p">()</span>
<span class="cp"># optimizer = torch.optim.SGD(logits.parameters(), lr=LR)  # optimize all cnn parameters</span>
<span class="cp"># optimizer.zero_grad()</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>  <span class="err">#</span> <span class="n">the</span> <span class="n">target</span> <span class="n">label</span> <span class="n">is</span> <span class="n">not</span> <span class="n">one</span><span class="o">-</span><span class="n">hotted</span>

<span class="n">Accurate</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Astore</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">bstore</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="n">logits</span><span class="p">.</span><span class="n">parameters</span><span class="p">()]</span>
<span class="n">A</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">b</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="k">for</span> <span class="n">e</span> <span class="n">in</span> <span class="n">range</span><span class="p">(</span><span class="n">EPOCH</span><span class="p">)</span><span class="o">:</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">b_y</span><span class="p">)</span> <span class="n">in</span> <span class="n">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="o">:</span>  <span class="err">#</span> <span class="n">gives</span> <span class="n">batch</span> <span class="n">data</span>
        <span class="n">b_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">).</span><span class="n">cuda</span><span class="p">()</span>  <span class="err">#</span> <span class="n">reshape</span> <span class="n">x</span> <span class="n">to</span> <span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">time_step</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span>
        <span class="n">b_y</span> <span class="o">=</span> <span class="n">b_y</span><span class="p">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">logits</span><span class="p">(</span><span class="n">b_x</span><span class="p">)</span>  <span class="err">#</span> <span class="n">logits</span> <span class="n">output</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">b_y</span><span class="p">)</span>  <span class="err">#</span> <span class="n">cross</span> <span class="n">entropy</span> <span class="n">loss</span>
        <span class="k">if</span> <span class="n">A</span><span class="p">.</span><span class="n">grad</span> <span class="n">is</span> <span class="n">not</span> <span class="n">None</span><span class="o">:</span>
            <span class="n">A</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="n">b</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>  <span class="err">#</span> <span class="n">backpropagation</span><span class="p">,</span> <span class="n">compute</span> <span class="n">gradients</span>

        <span class="n">A</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">A</span><span class="p">.</span><span class="n">data</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">A</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span>
        <span class="n">b</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="n">data</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">b</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">1500</span> <span class="o">==</span> <span class="mi">0</span><span class="o">:</span>
            <span class="n">test_output</span> <span class="o">=</span> <span class="n">logits</span><span class="p">(</span><span class="n">test_x</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>
            <span class="n">pred_y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="n">cuda</span><span class="p">().</span><span class="n">data</span><span class="p">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">Accurate</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="n">test_y</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span> <span class="o">==</span> <span class="n">pred_y</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">len</span><span class="p">(</span><span class="n">test_y</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())))</span>
            <span class="n">print</span><span class="p">(</span><span class="n">Accurate</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">Astore</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">detach</span><span class="p">())</span>
            <span class="n">bstore</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">detach</span><span class="p">())</span>
<span class="n">test_output</span> <span class="o">=</span> <span class="n">logits</span><span class="p">(</span><span class="n">test_x</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>
<span class="n">pred_y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="n">cuda</span><span class="p">().</span><span class="n">data</span><span class="p">.</span><span class="n">squeeze</span><span class="p">()</span>

<span class="n">print</span><span class="p">(</span><span class="n">pred_y</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">prediction</span> <span class="n">number</span><span class="err">&#39;</span><span class="p">)</span>
<span class="n">print</span><span class="p">(</span><span class="n">test_y</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">real</span> <span class="n">number</span><span class="err">&#39;</span><span class="p">)</span>
<span class="n">Accurate</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="n">test_y</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span> <span class="o">==</span> <span class="n">pred_y</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">len</span><span class="p">(</span><span class="n">test_y</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())))</span>
<span class="n">print</span><span class="p">(</span><span class="n">Accurate</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="n">range</span><span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">Astore</span><span class="p">))</span><span class="o">:</span>
    <span class="n">Astore</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">Astore</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">Astore</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]).</span><span class="n">norm</span><span class="p">()</span>
    <span class="n">bstore</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">bstore</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">bstore</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]).</span><span class="n">norm</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Astore</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sc">&#39;A&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bstore</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sc">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">cla</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Accurate</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<h1 id="_4">参考文献</h1>
</div>
<div id="content-footer">created in <span class="create-date date"> 2018-08-09 00:00 </span></div>
<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  title: 'Getting Started',
  owner: 'sthsf',
  repo: 'wiki',
  oauth: {
    client_id: '086c54c5fd95adfdc372',
    client_secret: '2ad9ebe87b952d2c77fccf99c334881b91eaa73d',
  },
  // ...
  // For more available options, check out the documentation below
})
gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

</div>
<div id="footer">
            <span>
                Copyright © 2019 LiYu.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
                Fork me in <a href="https://github.com/sthsf/wiki" target="_blank"> github </a>.
            </span>
</div>


<!--百度统计-->
<script>
    var _hmt = _hmt || [];
    (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?90e1dcdd1938573c19f9ff6521188e91";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>


</body>
</html>