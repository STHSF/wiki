<!DOCTYPE HTML>
<html>
<head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <title>XGBoost GPU安装 - LiYu's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Economics"/>
    <meta name="description" content="A wiki website of sthsf when I learned new knowledgy and technics."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width" />

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)']]}
        });
        </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-78529611-1', 'auto');
        ga('send', 'pageview');

    </script>
</head>

<body>
<div id="container">
    
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#Algorithm">Algorithm</a>&nbsp;»&nbsp;<a href="/wiki/#Algorithm-EnsembleMethod">EnsembleMethod</a>&nbsp;»&nbsp;<a href="/wiki/#Algorithm-EnsembleMethod-EnsembleLearning">EnsembleLearning</a>&nbsp;»&nbsp;XGBoost GPU安装</div>
</div>
<div class="clearfix"></div>
<div id="title">XGBoost GPU安装</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">写在前面</a></li>
<li><a href="#_2">单机部署</a><ul>
<li><a href="#1">1、下载源码</a></li>
<li><a href="#2build">2、新建build文件目录</a></li>
<li><a href="#3">3、编译源码</a></li>
<li><a href="#4make">4、make</a></li>
<li><a href="#virtualenvxgboost">virtualenv中更新XGBoost</a></li>
</ul>
</li>
<li><a href="#xgboostgpu">XGBoost的多GPU部署</a><ul>
<li><a href="#nccl2">NCCL2安装</a></li>
<li><a href="#_3">多卡运行测试</a></li>
</ul>
</li>
<li><a href="#_4">注意点</a><ul>
<li><a href="#1cmake">1、cmake 版本更新</a></li>
<li><a href="#2xgboost-gpu-python35">2、安装XGBoost gpu版本, python的版本必须大于3.5</a></li>
<li><a href="#xgboost_gpu">XGBoost_GPU使用</a></li>
</ul>
</li>
<li><a href="#_5">参考文献</a></li>
</ul>
</div>
<h1 id="_1">写在前面</h1>
<p>随着业务场景的慢慢深入, 数据量的逐步增大, 模型的训练时间不断的变长, 导致模型训练成本逐步增大. 所以需要更加高效的提高硬件计算资源的利用率, 本文主要介绍安装GPU版本的XGBoost.</p>
<h1 id="_2">单机部署</h1>
<p>安装前提是需要GPU驱动, cudnn等安装正确, 如果这步没有安装, 请参见<a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---Tensorflow-gpu%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85(2).html">Ubuntu16.04下安装安装CUDA9.0、cuDNN7.0和tensotflow-gpu 1.8.0以上的版本流程和问题总结</a>的具体安装方式.</p>
<h3 id="1">1、下载源码</h3>
<p>在git clone下来的xgboost中执行</p>
<div class="hlcode"><pre><span class="n">git</span> <span class="n">submodule</span> <span class="n">init</span>
<span class="n">git</span> <span class="n">submodule</span> <span class="n">update</span>
</pre></div>


<p>更新子依赖, 或者使用:</p>
<div class="hlcode"><pre><span class="n">git</span> <span class="n">clone</span> <span class="o">--</span><span class="n">recursive</span> <span class="n">https</span><span class="o">:</span><span class="c1">//github.com/dmlc/xgboost</span>
</pre></div>


<h3 id="2build">2、新建build文件目录</h3>
<p>在/xgboost, 目录下新建/build文件夹</p>
<div class="hlcode"><pre><span class="n">cd</span> <span class="n">xgboost</span>
<span class="n">mkdir</span> <span class="n">build</span>
</pre></div>


<h3 id="3">3、编译源码</h3>
<p>执行cmake</p>
<div class="hlcode"><pre><span class="n">cmake</span> <span class="p">..</span> <span class="o">-</span><span class="n">DUSE_CUDA</span><span class="o">=</span><span class="n">ON</span>
</pre></div>


<p>执行结果如下图所示:<br />
<center><img src="/wiki/static/images/essemble/xgboost/xgboost_3.jpg" alt="xgboost-3"/></center></p>
<h3 id="4make">4、make</h3>
<p>执行make</p>
<div class="hlcode"><pre><span class="n">make</span> <span class="o">-</span><span class="n">j4</span>
</pre></div>


<p>执行过程和执行结果如下图:<br />
<center><img src="/wiki/static/images/essemble/xgboost/xgboost_4.jpg" alt="xgboost-4"/></center></p>
<p><center><img src="/wiki/static/images/essemble/xgboost/xgboost_5.jpg" alt="xgboost-5"/></center></p>
<p><strong><em>PS</em></strong>很多教程中提到, 在make的过程中不需要用到-j4中的4, 他的解释是使用后会自动生成build目录, 但是我的理解是在新建的build目录下执行上面的命令, 所以不太理解他的做法, 另外我在pull源码下来后, 源码里事先没有build文件目录, 需要手动新建.</p>
<h2 id="virtualenvxgboost">virtualenv中更新XGBoost</h2>
<p>一般的, 为了不污染原始环境, 我们都会使用虚拟环境隔离开发环境, 比如virtualenv或conda. 我使用的是vitrualenv, 所以介绍virtualenv中如何更新, 其实方式比较简单.</p>
<p>直接<code>pip uninstall XGBoost</code>先卸载掉原始的XGBoost 然后重新安装即可. 虚拟环境下可以完美调用GPU运行XGBoost.<br />
调用情况如下:<br />
<center><img src="/wiki/static/images/essemble/xgboost/xgboost_6.jpg" alt="xgboost-6"/></center></p>
<p>annaconda下面没有测试过, 可能也需要重新安装.</p>
<h1 id="xgboostgpu">XGBoost的多GPU部署</h1>
<p>[UPDATE20190710]<br />
上面的初始化过程中, 是不能使用分布式GPU进行计算的, 而且只能使用单个的GPU, 为了能够使用分布式GPU训练, 需要设置USE_NCCL=ON, 另外, 分布式GPU训练依赖Nvidia的<a href="https://developer.nvidia.com/nccl">NCCL2</a>, 需要另外安装. 特别的, 目前NCCL2只支持linux系统, 所以分布式GPU训练只支持linux系统.</p>
<p>详细的安装方式:</p>
<div class="hlcode"><pre><span class="n">mkdir</span> <span class="n">build</span>
<span class="n">cd</span> <span class="n">build</span>
<span class="n">cmake</span> <span class="p">..</span> <span class="o">-</span><span class="n">DUSE_CUDA</span><span class="o">=</span><span class="n">ON</span> <span class="o">-</span><span class="n">DUSE_NCCL</span><span class="o">=</span><span class="n">ON</span> <span class="o">-</span><span class="n">DNCCL_ROOT</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">nccl2</span>
<span class="n">make</span> <span class="o">-</span><span class="n">j4</span>
</pre></div>


<p>我在配置安装过程时, 使用的命令:</p>
<div class="hlcode"><pre><span class="o">-</span><span class="n">DNCCL_ROOT</span><span class="o">=/</span><span class="n">usr</span><span class="o">/</span><span class="n">include</span>
</pre></div>


<p><strong>PS</strong>, 这里的分布式GPU训练, 笔者认为是单服务器多GPU训练, 并不是我们所谓的分布式服务器的方式, 不过暂时还没有验证.</p>
<h2 id="nccl2">NCCL2安装</h2>
<p>NCCL是Nvidia Collective multi-GPU Communication Library的简称，它是一个实现多GPU的collective communication通信库，Nvidia做了很多优化，以在PCIe、Nvlink、InfiniBand上实现较高的通信速度。</p>
<ul>
<li>
<p>1、登陆<a href="https://developer.nvidia.com/nccl">NCCL官网</a>, 进行NCCL下载或者复制下载链接, 需要进行注册, 之前注册过的直接登陆即可.<br />
<center><img src="/wiki/static/images/essemble/xgboost/nccldownload.jpg" alt="xgboost-6"/></center></p>
</li>
<li>
<p>2、点击下载, 进入NCCL下载页面.<br />
<center><img src="/wiki/static/images/essemble/xgboost/nccldownload1.jpg" alt="xgboost-6"/></center></p>
</li>
<li>
<p>3、根据原先安装的cuda和cudnn版本以及操作系统版本, 选择对应的NCCL版本. 我们这里是根据ubuntu16.04和cuda10.0, 选择下载的版本是nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb<br />
<center><img src="/wiki/static/images/essemble/xgboost/libnccl.jpg" alt="xgboost-6"/></center></p>
</li>
<li>
<p>4、切换到NCCL下载的文件目录, 使用下面的命令进行安装</p>
</li>
</ul>
<div class="hlcode"><pre><span class="n">dpkg</span> <span class="o">-</span><span class="n">i</span> <span class="n">nvidia</span><span class="o">-</span><span class="n">machine</span><span class="o">-</span><span class="n">learning</span><span class="o">-</span><span class="n">repo</span><span class="o">-</span><span class="n">ubuntu1604_1</span><span class="mf">.0.0</span><span class="o">-</span><span class="mi">1</span><span class="n">_amd64</span><span class="p">.</span><span class="n">deb</span>
</pre></div>


<ul>
<li>5、更新APT数据库：<code>sudo apt update</code>, 这一步需要操作, 不然第六步会安装不成功,</li>
<li>6、利用APT安装libnccl2。<br />
此外，如果您需要使用NCCL编译应用程序，则同时安装 libnccl-dev包。</li>
</ul>
<p>如果您正在使用网络存储库，则使用以下命令。这种不推荐.</p>
<div class="hlcode"><pre><span class="err">　　</span><span class="n">sudo</span> <span class="n">apt</span> <span class="n">install</span> <span class="n">libnccl2</span> <span class="n">libnccl</span><span class="o">-</span><span class="n">dev</span>
</pre></div>


<p>如果您希望保留较旧版本的CUDA，请指定特定版本，例如上图第二个框框中的内容：</p>
<div class="hlcode"><pre><span class="err">　　</span><span class="n">sudo</span> <span class="n">apt</span> <span class="n">install</span> <span class="n">libnccl2</span><span class="o">=</span><span class="mf">2.4.7</span><span class="o">-</span><span class="mi">1</span><span class="o">+</span><span class="n">cuda10</span><span class="mf">.0</span> <span class="n">libnccl</span><span class="o">-</span><span class="n">dev</span><span class="o">=</span><span class="mf">2.4.7</span><span class="o">-</span><span class="mi">1</span><span class="o">+</span><span class="n">cuda10</span><span class="mf">.0</span>
</pre></div>


<p>请参阅<a href="https://docs.nvidia.com/deeplearning/sdk/nccl-install-guide/index.html">官网安装手册</a>以了解确切的软件包版本。</p>
<ul>
<li>7、链接到正常位置<br />
完成解压安装，将NCCL的include 和lib 文件夹下文件放到对应 /usr/local/include /usr/local/lib 目录下。 </li>
</ul>
<div class="hlcode"><pre><span class="n">sudo</span> <span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="n">nccl</span><span class="o">/</span><span class="n">lib</span>
<span class="n">sudo</span> <span class="n">ln</span> <span class="o">-</span><span class="n">s</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">x86_64</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">gnu</span><span class="o">/</span><span class="n">libnccl</span><span class="p">.</span><span class="n">so</span><span class="mf">.2</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="n">nccl</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span>
<span class="n">sudo</span> <span class="n">ln</span> <span class="o">-</span><span class="n">s</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">x86_64</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">gnu</span><span class="o">/</span><span class="n">libcudnn</span><span class="p">.</span><span class="n">so</span><span class="mf">.7</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="n">lib64</span><span class="o">/</span>
</pre></div>


<p>执行下面的命令:</p>
<div class="hlcode"><pre><span class="n">cat</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">include</span><span class="o">/</span><span class="n">cudnn</span><span class="p">.</span><span class="n">h</span> <span class="o">|</span> <span class="n">grep</span> <span class="n">CUDNN_MAJOR</span> <span class="o">-</span><span class="n">A</span> <span class="mi">2</span>
</pre></div>


<p>执行效果如下:</p>
<div class="hlcode"><pre><span class="n">ubuntu</span><span class="err">@</span><span class="n">AiDLHost</span><span class="o">:~</span><span class="err">$</span> <span class="n">cat</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">include</span><span class="o">/</span><span class="n">cudnn</span><span class="p">.</span><span class="n">h</span> <span class="o">|</span> <span class="n">grep</span> <span class="n">CUDNN_MAJOR</span> <span class="o">-</span><span class="n">A</span> <span class="mi">2</span>
<span class="cp">#define CUDNN_MAJOR 7</span>
<span class="cp">#define CUDNN_MINOR 5</span>
<span class="cp">#define CUDNN_PATCHLEVEL 1</span>
<span class="o">--</span>
<span class="cp">#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)</span>

<span class="cp">#include &quot;driver_types.h&quot;</span>
</pre></div>


<h2 id="_3">多卡运行测试</h2>
<p>nccl的安装教程不多, 也没有提供什么测试案例, 所以只能直接运行xgboost,观察多张卡的使用情况, 我使用xgboost源码下的demo进行测试:<br />
测试demo:<br />
<code>~/xgboost/demo/gpu_acceleration</code><br />
运行之前查看GPU的状态:<br />
<center><img src="/wiki/static/images/essemble/xgboost/nccl_4_1.png" alt="xgboost-4_1"/></center></p>
<p>运行过程中查看GPU的运行状态:<br />
<center><img src="/wiki/static/images/essemble/xgboost/nccl_4.jpg" alt="xgboost-4"/></center></p>
<p>从上图中可以看出demo运行过程中4张卡都被占用. 所以应该是安装成功了(ps没有在未安装nccl2之前尝试运行demo, 所以不确定是不是nccl2起作用了).</p>
<p>另外, demo的运行结果:</p>
<div class="hlcode"><pre><span class="p">[</span><span class="mi">2996</span><span class="p">]</span>  <span class="n">test</span><span class="o">-</span><span class="n">merror</span><span class="o">:</span><span class="mf">0.031765</span>
<span class="p">[</span><span class="mi">2997</span><span class="p">]</span>  <span class="n">test</span><span class="o">-</span><span class="n">merror</span><span class="o">:</span><span class="mf">0.031758</span>
<span class="p">[</span><span class="mi">2998</span><span class="p">]</span>  <span class="n">test</span><span class="o">-</span><span class="n">merror</span><span class="o">:</span><span class="mf">0.031751</span>
<span class="p">[</span><span class="mi">2999</span><span class="p">]</span>  <span class="n">test</span><span class="o">-</span><span class="n">merror</span><span class="o">:</span><span class="mf">0.031772</span>
<span class="n">GPU</span> <span class="n">Training</span> <span class="n">Time</span><span class="o">:</span> <span class="mf">241.86946082115173</span> <span class="n">seconds</span>
</pre></div>


<p>从运行结果可以看出, 相同的迭代次数下, GPU的运行时间大大缩短.</p>
<h1 id="_4">注意点</h1>
<h3 id="1cmake">1、cmake 版本更新</h3>
<p>在编译过程中,可能会出现下面的问题, 原因是cmake的版本太低, 需要更新cmake版本.</p>
<div class="hlcode"><pre><span class="n">CMake</span> <span class="n">Error</span> <span class="n">at</span> <span class="n">CMakeLists</span><span class="p">.</span><span class="n">txt</span><span class="o">:</span><span class="mi">62</span> <span class="p">(</span><span class="n">cmake_minimum_required</span><span class="p">)</span><span class="o">:</span>
  <span class="n">CMake</span> <span class="mf">3.12</span> <span class="n">or</span> <span class="n">higher</span> <span class="n">is</span> <span class="n">required</span><span class="p">.</span>  <span class="n">You</span> <span class="n">are</span> <span class="n">running</span> <span class="n">version</span> <span class="mf">3.5.1</span>
</pre></div>


<p>版本更新教程见<a href="https://askubuntu.com/questions/829310/how-to-upgrade-cmake-in-ubuntu">StackExcahnge</a><br />
简单的安装步骤:</p>
<div class="hlcode"><pre><span class="n">step</span> <span class="mi">0</span><span class="o">:</span> <span class="n">sudo</span> <span class="n">apt</span> <span class="n">remove</span> <span class="n">cmake</span>
<span class="n">step</span> <span class="mi">1</span><span class="o">:</span> <span class="n">cd</span> <span class="o">/</span><span class="n">opt</span>
<span class="n">step</span> <span class="mi">2</span><span class="o">:</span> <span class="n">wget</span> <span class="n">https</span><span class="o">:</span><span class="c1">//github.com/Kitware/CMake/releases/download/v3.15.0-rc3/cmake-3.15.0-rc3-Linux-x86_64.sh</span>
<span class="n">step</span> <span class="mi">3</span><span class="o">:</span> <span class="n">chmod</span> <span class="o">+</span><span class="n">x</span> <span class="n">cmake</span><span class="o">-</span><span class="mf">3.</span><span class="o">*</span><span class="n">your_version</span><span class="o">*</span><span class="p">.</span><span class="n">sh</span>
<span class="n">step</span> <span class="mi">4</span><span class="o">:</span> <span class="n">sudo</span> <span class="n">bash</span> <span class="n">cmake</span><span class="o">-</span><span class="mf">3.</span><span class="o">*</span><span class="n">your_version</span><span class="o">*</span><span class="p">.</span><span class="n">sh</span>
<span class="n">step</span> <span class="mi">5</span><span class="o">:</span> <span class="n">sudo</span> <span class="n">ln</span> <span class="o">-</span><span class="n">s</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">cmake</span><span class="o">-</span><span class="mf">3.</span><span class="o">*</span><span class="n">your_version</span><span class="err">*/</span><span class="n">bin</span><span class="o">/*</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">bin</span>
</pre></div>


<h3 id="2xgboost-gpu-python35">2、安装XGBoost gpu版本, python的版本必须大于3.5</h3>
<p>报错如下:</p>
<div class="hlcode"><pre><span class="n">RuntimeError</span><span class="o">:</span> <span class="n">Python</span> <span class="n">version</span> <span class="o">&gt;=</span> <span class="mf">3.5</span> <span class="n">required</span><span class="o">.</span>
</pre></div>


<h2 id="xgboost_gpu">XGBoost_GPU使用</h2>
<p>[UPDATA20190710]<br />
在使用gpu训练XGBoost模型的时候, 如果training params中的max_depth设置过高, 可能会引起服务器内存过高的问题.</p>
<h1 id="_5">参考文献</h1>
<p><a href="https://xgboost.readthedocs.io/en/latest/build.html#building-with-gpu-support">Installation Guide</a></p>
<p><a href="https://blog.csdn.net/wl2858623940/article/details/80546140">linux下安装XGBoost并支持GPU（anaconda3）</a></p>
<p><a href="https://blog.csdn.net/u011587516/article/details/78995186">ubuntu安装xgboost，CPU版和GPU版配置</a></p>
<p><a href="https://blog.csdn.net/voidfaceless/article/details/78338678">GPU加速xgboost——win10下配置</a></p>
<p><a href="https://blog.csdn.net/Perfect_Accepted/article/details/81989486">Ubuntu16.04安装GPU版xgboost</a></p>
<p><a href="https://www.cnblogs.com/kdyi/p/10636988.html">xgboost 多gpu支持 编译</a></p>
<p><a href="https://github.com/PaddlePaddle/Paddle/wiki/NCCL2-Survey">NCCL2 Survey</a></p>
<p><a href="http://blog.fangchengjin.cn/ubuntu-nccl2.html">Ubuntu 16.04安装NCCL 2</a></p>
<p><a href="https://docs.ksyun.com/documents/2593">安装cuDNN和NCCL指南</a></p>
<p><a href="https://www.ncnynl.com/archives/201905/3061.html">深度学习入门教程-Ubuntu18.04系统安装cuDNN7和NCCL2</a></p>
</div>
<div id="content-footer">created in <span class="create-date date"> 2019-07-08 00:00 </span></div>
<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  title: 'XGBoost GPU安装',
  owner: 'sthsf',
  repo: 'wiki',
  oauth: {
    client_id: '086c54c5fd95adfdc372',
    client_secret: '2ad9ebe87b952d2c77fccf99c334881b91eaa73d',
  },
  // ...
  // For more available options, check out the documentation below
})
gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

</div>
<div id="footer">
            <span>
                Copyright © 2019 LiYu.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
                Fork me in <a href="https://github.com/sthsf/wiki" target="_blank"> github </a>.
            </span>
</div>


<!--百度统计-->
<script>
    var _hmt = _hmt || [];
    (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?90e1dcdd1938573c19f9ff6521188e91";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>


</body>
</html>