<!DOCTYPE HTML>
<html>
<head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <title>Mathine Learning Tricks - 特征工程之归一化方法(Normalization Method) - LiYu's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Economics"/>
    <meta name="description" content="A wiki website of sthsf when I learned new knowledgy and technics."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width" />

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)']]}
        });
        </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-78529611-1', 'auto');
        ga('send', 'pageview');

    </script>
</head>

<body>
<div id="container">
    
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#Algorithm">Algorithm</a>&nbsp;»&nbsp;<a href="/wiki/#Algorithm-MachineLearning">MachineLearning</a>&nbsp;»&nbsp;Mathine Learning Tricks - 特征工程之归一化方法(Normalization Method)</div>
</div>
<div class="clearfix"></div>
<div id="title">Mathine Learning Tricks - 特征工程之归一化方法(Normalization Method)</div>
<div id="content">
  <h1 id="_1">特征工程</h1>
<p>数据预处理在众多深度学习算法中都起着重要作用，实际情况中，将数据做归一化和白化处理后，很多算法能够发挥最佳效果。然而除非对这些算法有丰富的使用经验，否则预处理的精确参数并非显而易见。</p>
<h2 id="1feature-scalingnormalization">1、Feature Scaling（normalization）</h2>
<p>让不同的输入特征数据具有相同的分布，即使数据集中的所有特征都具有零均值和单位方差，这样在梯度下降中更新参数时效率更高。</p>
<h3 id="_2">方法</h3>
<p>scaling的方法很多种，其中之一就是求特征向量每个维度的均值和方差。<br />
假设对于样本数据集$(X=[X^1, X^2, X^3, ....,X^r])$, 其中$(X^r=[x_1^r, x_2^r, x_3^r, ..., x_i^r])$<br />
分别求每一个维度$(i)$的均值和方差。<br />
- mean: $(m_i)$<br />
- standard deviation: $(\sigma_i)$<br />
则，每个特征元素可重新表示为：<br />
$$<br />
x_i^r=\frac{x_i^r-m_i}{\sigma_i}<br />
$$<br />
修改后是的每个维度数据的均值为0，方差为1。</p>
<h2 id="_3"></h2>
<p>最小冗余最大关联特征选择</p>
<p>将所有的想法整合起来就能得出我们的算法，即 mRMR 特征选择。算法背后的考虑是，同时最小化特征的冗余并最大化特征的关联。因此，我们需要计算冗余和关联的方程：</p>
<p>冗余:</p>
<p>$$<br />
Relevance = \frac{ \sum_{i=1}^{n}c_ix_i}{\sum_{i=1}^nx_i}<br />
$$</p>
<p>关联:</p>
<p>$$<br />
Redundancy = \frac{\sum_{i,j=1}^na_{ij}x_ix_j}{(\sum_{i=1}^nx_i)^2}<br />
$$</p>
<p>让我们用虚构的数据写一个快速脚本来实现 mRMR：</p>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">12</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">15</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">25</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">20</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">23</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">18</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">20</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">16</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">12</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>

<span class="p">])</span>

<span class="n">corrcoef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">matrix</span><span class="p">))</span>
<span class="n">relevancy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">corrcoef</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>

<span class="c"># set initial to all dimensions on</span>
<span class="n">x0</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>

<span class="c"># minimize the redundancy minus relevancy</span>
<span class="n">fun</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">sum</span><span class="p">([</span><span class="n">corrcoef</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))])</span> <span class="o">/</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">relevancy</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>

<span class="k">print</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
</pre></div>


<p>一般做机器学习应用的时候大部分时间是花费在特征处理上，其中很关键的一步就是对特征数据进行归一化，为什么要归一化呢？很多同学并未搞清楚，维基百科给出的解释：<br />
- 归一化后加快了梯度下降求最优解的速度;如果机器学习模型使用梯度下降法求最优解时，归一化往往非常有必要，否则很难收敛甚至不能收敛。</p>
<ul>
<li>归一化有可能提高精度;<br />
一些分类器需要计算样本之间的距离（如欧氏距离），例如KNN。如果一个特征值域范围非常大，那么距离计算就主要取决于这个特征，从而与实际情况相悖（比如这时实际情况是值域范围小的特征更重要）。</li>
</ul>
<h1 id="k-folds">K-folds交叉验证</h1>
<p>交叉验证的基本思想是把在某种意义下将原始数据进行分组, 一部分作为训练集, 另一部分作为验证集.</p>
<p>K折交叉验证, 就是把原始数据(初始采样)分割成K个子集, 将其中一个子集作为验证集, 其余K-1个子集作为训练集. 交叉验证重复K次, 每个子集验证一次, 将K次结果通平均或者其他的某种方式最终得到一个单一的估测, 以此来作为评价分类器的性能指标.</p>
<p>交叉验证的好处是防止过拟合,挑选最合适的模型.</p>
<h3 id="stratifiedkfold">StratifiedKFold实例</h3>
<p>简要介绍sklern中的StratifiedKFold用法</p>
<h4 id="stratifiedkfold_1">StratifiedKFold参数说明</h4>
<ul>
<li>n_splits:折叠次数，默认为3，至少为2。</li>
<li>shuffle:是否在每次分割之前打乱顺序。</li>
<li>random_state:随机种子，在shuffle==True时使用，默认使用np.random。</li>
</ul>
<h4 id="sklearn">sklearn</h4>
<div class="hlcode"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">lightgbm</span> <span class="kn">as</span> <span class="nn">lgb</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">&#39;ignore&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_data</span><span class="p">():</span>
    <span class="n">train</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">&#39;/home/kesci/input/round11379/train_round_1.csv&#39;</span><span class="p">)</span>
    <span class="n">test</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">&#39;/home/kesci/input/round11379/test_round_1.csv&#39;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="k">def</span> <span class="nf">split_train_test</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">&#39;purchase&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">&#39;purchase&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">submit</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[[</span><span class="s">&#39;user_id&#39;</span><span class="p">,</span><span class="s">&#39;Product_id&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;user_id&#39;</span><span class="p">,</span><span class="s">&#39;Product_id&#39;</span><span class="p">,</span><span class="s">&#39;seller&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;user_id&#39;</span><span class="p">,</span><span class="s">&#39;Product_id&#39;</span><span class="p">,</span><span class="s">&#39;seller&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;purchase&#39;</span><span class="p">,</span><span class="s">&#39;favorite&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_data</span><span class="p">,</span><span class="n">test_data</span><span class="p">,</span><span class="n">submit</span>


<span class="k">def</span> <span class="nf">train_lgb</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span><span class="n">test_y</span><span class="p">,</span><span class="n">res</span><span class="p">,</span><span class="n">col</span><span class="p">):</span>
    <span class="n">kfold</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2019</span><span class="p">)</span> <span class="c">#shuffle:是否在每次分割之前打乱顺序</span>
    <span class="n">lgb_paras</span> <span class="o">=</span><span class="p">{</span>
        <span class="s">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s">&#39;boosting_type&#39;</span><span class="p">:</span> <span class="s">&#39;gbdt&#39;</span><span class="p">,</span>
        <span class="s">&#39;objective&#39;</span><span class="p">:</span> <span class="s">&#39;binary&#39;</span><span class="p">,</span>
        <span class="s">&#39;metric&#39;</span><span class="p">:</span> <span class="s">&#39;auc&#39;</span><span class="p">,</span>
        <span class="s">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="mi">63</span><span class="p">,</span>
        <span class="s">&#39;feature_fraction&#39;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="s">&#39;bagging_fraction&#39;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="s">&#39;bagging_freq&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
        <span class="s">&#39;seed&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s">&#39;bagging_seed&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s">&#39;feature_fraction_seed&#39;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span>
        <span class="s">&#39;min_data_in_leaf&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
        <span class="s">&#39;nthread&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="s">&#39;verbose&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span>
    <span class="p">}</span>
    <span class="n">scores</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">test_pred</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_x</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">n_fold</span><span class="p">,(</span><span class="n">tr_idx</span><span class="p">,</span> <span class="n">val_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kfold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">&#39;the {n_fold} training start ...&#39;</span><span class="p">)</span>
        <span class="n">tr_x</span><span class="p">,</span> <span class="n">tr_y</span><span class="p">,</span> <span class="n">val_x</span><span class="p">,</span> <span class="n">val_y</span> <span class="o">=</span> <span class="n">train_x</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">tr_idx</span><span class="p">],</span> <span class="n">train_y</span><span class="p">[</span><span class="n">tr_idx</span><span class="p">],</span> <span class="n">train_x</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_idx</span><span class="p">],</span> <span class="n">train_y</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span>
        <span class="n">train_set</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">tr_x</span><span class="p">,</span> <span class="n">tr_y</span><span class="p">)</span>
        <span class="n">val_set</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">val_x</span><span class="p">,</span> <span class="n">val_y</span><span class="p">)</span>
        <span class="n">lgb_model</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">lgb_paras</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span>
                              <span class="n">valid_sets</span><span class="o">=</span><span class="p">[</span><span class="n">val_set</span><span class="p">],</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">40000</span><span class="p">,</span> <span class="n">verbose_eval</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
        <span class="n">val_pred</span> <span class="o">=</span> <span class="n">lgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">val_x</span><span class="p">,</span> <span class="n">num_iteration</span><span class="o">=</span><span class="n">lgb_model</span><span class="o">.</span><span class="n">best_iteration</span><span class="p">)</span>
        <span class="n">test_pred</span><span class="o">+=</span><span class="n">lgb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">test_x</span><span class="p">,</span> <span class="n">num_iteration</span><span class="o">=</span><span class="n">lgb_model</span><span class="o">.</span><span class="n">best_iteration</span><span class="p">)</span><span class="o">/</span> <span class="n">kfold</span><span class="o">.</span><span class="n">n_splits</span>
        <span class="n">val_score</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">val_pred</span><span class="p">)</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_score</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&#39;cv: &#39;</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&#39;cv : &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
    <span class="n">res</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">=</span><span class="n">test_pred</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">fea</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;purchase&#39;</span><span class="p">,</span> <span class="s">&#39;favorite&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">fea</span> <span class="o">==</span> <span class="s">&#39;purchase&#39;</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span>
            <span class="n">train</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">submit_purchase</span> <span class="o">=</span> <span class="n">split_train_test</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">train_x</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;purchase&#39;</span><span class="p">,</span> <span class="s">&#39;favorite&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">train_y</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">&#39;purchase&#39;</span><span class="p">]</span>
            <span class="n">submit_purchase</span> <span class="o">=</span> <span class="n">train_lgb</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">submit_purchase</span><span class="p">,</span> <span class="s">&#39;purchase&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">data</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span>
            <span class="n">submit_purchase</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;user_id&#39;</span><span class="p">,</span> <span class="s">&#39;product_id&#39;</span><span class="p">,</span> <span class="s">&#39;pred_purchase&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span>
            <span class="n">train</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">submit_favorite</span> <span class="o">=</span> <span class="n">split_train_test</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">train_x</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;purchase&#39;</span><span class="p">,</span> <span class="s">&#39;favorite&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">train_y</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">&#39;favorite&#39;</span><span class="p">]</span>
            <span class="n">submit_favorite</span> <span class="o">=</span> <span class="n">train_lgb</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">submit_favorite</span><span class="p">,</span> <span class="s">&#39;favorite&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">data</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span>
            <span class="n">submit_favorite</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;user_id&#39;</span><span class="p">,</span> <span class="s">&#39;product_id&#39;</span><span class="p">,</span> <span class="s">&#39;pred_favorite&#39;</span><span class="p">]</span>
</pre></div>


<h3 id="timeseriessplit">TimeSeriesSplit实例</h3>
<p>对于时间序列的数据类型, 这种数据具有高度的自相关性, 前后相邻时段的数据关联程度非常高. 使用简单随机抽样的方式对时间序列数据采样容易破坏其时段的连续性, 同时,也有可能引入未来数据.</p>
<h4 id="sklearn_1">sklearn</h4>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">TimeSeriesSplit</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>

<span class="n">kf</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="k">for</span> <span class="n">train</span><span class="p">,</span><span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="s">&#39;</span><span class="se">\n</span><span class="s">&#39;</span><span class="p">,</span><span class="n">test</span><span class="p">)</span>
</pre></div>


<p><a href="https://blog.csdn.net/cherdw/article/details/54986863">Sklearn-CrossValidation交叉验证</a></p>
<p><a href="https://blog.csdn.net/jasonding1354/article/details/50562513">交叉验证及其用于参数选择、模型选择、特征选择的例子</a></p>
<p><a href="http://www.mtcnn.com/?p=517">tensorflow数据归一化，z-score,min-max几种方法</a></p>
<p><a href="https://blog.csdn.net/weixin_44110891/article/details/95240937">k折交叉验证sklearn中的StratifiedKFold</a></p>
<p><a href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation">Cross-validation: evaluating estimator performance</a></p>
<h1 id="_4">特征选择</h1>
<p>特征选择防止模型过拟合降低模型的泛化误差, 可以减少硬件资源的损耗, 降低模型的开发成本, 减少训练时间.</p>
<h3 id="_5">过拟合</h3>
<p>如果一个模型在训练集上的表现明显高于测试集上, 则说明模型可能过拟合了.</p>
<p>过拟合是指模型的参数对于对于训练数据的特定观测值拟合的非常接近, 而训练数据的分布与真实数据的分布并不一致, 所以模型具有较高的方差.</p>
<p>产生过拟合的原因是对于训练集上的模型过于复杂.</p>
<p>降低模型过拟合的方法<br />
- 准备更多的训练数据<br />
- 引入正则化惩罚项<br />
- 降低模型的复杂度, 选择一个模型参数相对较少的模型<br />
- 降低数据的维度</p>
<h1 id="_6">参考文献</h1>
<p>https://www.cnblogs.com/sddai/p/6250094.html</p>
<p><a href="http://www.zhuanzhi.ai/document/a63d9faf42e18c06b5e8d4c9e3735840">异常检测论文大列表：方法、应用、综述</a></p>
</div>
<div id="content-footer">created in <span class="create-date date"> 2017-07-18 14:00 </span></div>
<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  title: 'Mathine Learning Tricks - 特征工程之归一化方法(Normalization Method)',
  owner: 'sthsf',
  repo: 'wiki',
  oauth: {
    client_id: '086c54c5fd95adfdc372',
    client_secret: '2ad9ebe87b952d2c77fccf99c334881b91eaa73d',
  },
  // ...
  // For more available options, check out the documentation below
})
gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

</div>
<div id="footer">
            <span>
                Copyright © 2020 LiYu.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
                Fork me in <a href="https://github.com/sthsf/wiki" target="_blank"> github </a>.
            </span>
</div>


<!--百度统计-->
<script>
    var _hmt = _hmt || [];
    (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?90e1dcdd1938573c19f9ff6521188e91";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>


</body>
</html>