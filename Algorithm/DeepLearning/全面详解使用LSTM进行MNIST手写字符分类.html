<!DOCTYPE HTML>
<html>
<head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <title>全面详解Tensorflow使用LSTM进行MNIST手写字符分类 - LiYu's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Economics"/>
    <meta name="description" content="A wiki website of sthsf when I learned new knowledgy and technics."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width" />

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)']]}
        });
        </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-78529611-1', 'auto');
        ga('send', 'pageview');

    </script>
</head>

<body>
<div id="container">
    
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#Algorithm">Algorithm</a>&nbsp;»&nbsp;<a href="/wiki/#Algorithm-DeepLearning">DeepLearning</a>&nbsp;»&nbsp;全面详解Tensorflow使用LSTM进行MNIST手写字符分类</div>
</div>
<div class="clearfix"></div>
<div id="title">全面详解Tensorflow使用LSTM进行MNIST手写字符分类</div>
<div id="content">
  <h1 id="_1">写在前面</h1>
<p>使用LSTM进行MNIST手写字符分类的Tensorflow代码其官方教程中就已经给出，很多其他的教程中也就把他拿过来作为lstm在分类中的应用作为讲解，但是很多代码依然是基于tensorflow官网代码。<br />
本教程中主要的代码跟官网没有差别，比如rnn_cell的定义，超参的设置也基本相同，本文主要的侧重点在给出了training_model和testing_model,并且结合tensorboard将训练和测试过程中的accuracy和loss展现出来。<br />
这里面涉及的主要问题是训练模型和测试模型的参数共享，以及tf.summary的应用。</p>
<p>我们先看下正确的结果：</p>
<h3 id="accuracy-cost">模型训练和测试的accuracy 和cost</h3>
<p><center><img src="/wiki/static/images/mnist/train_test.png" alt="scalaers" height="600" width="600"/></center></p>
<h3 id="tensorboard-graphs">tensorboard 中的GRAPHS</h3>
<p><center><img src="/wiki/static/images/mnist/graphs.png" alt="GRAPHS" height="250" width="250"/></center></p>
<h3 id="graph">GRAPH展开</h3>
<p><center><img src="/wiki/static/images/mnist/graph_unrolling.png" alt="GRAPHS_UNROLLING" height="600" width="600"/></center></p>
<p>上面所展现的也是本文所做的主要工作，也是实现过程中踩过的坑，为了防止模型的过拟合，tensorflow提供了droupout机制，在训练过程中drop掉某些节点来防止过拟合，但是测试模型并不需要使用到dorp以及一些train_op,因此有的教程中会将is_training作为模型的一个变量。<br />
首先将train_model和test_model分开定义,主要是为了便于使用tf.summary将训练模型和测试模型的accuracy和cost分别展现出来。</p>
<div class="hlcode"><pre><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">(</span><span class="o">-</span><span class="n">train_conf</span><span class="o">.</span><span class="n">init_scale</span><span class="p">,</span> <span class="n">train_conf</span><span class="o">.</span><span class="n">init_scale</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">&quot;Train&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">train_scope</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">&quot;Model&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">):</span>
            <span class="n">train_model</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_scope</span><span class="p">,</span> <span class="n">train_conf</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">&quot;Test&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">test_scope</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">&quot;Model&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">):</span>
            <span class="n">test_model</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_scope</span><span class="p">,</span> <span class="n">valid_conf</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
        <span class="n">train_summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="s">&#39;./model/tensorflowlogs/train&#39;</span><span class="p">,</span> <span class="n">session</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
        <span class="n">test_summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="s">&#39;./model/tensorflowlogs/test&#39;</span><span class="p">)</span>
        <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
</pre></div>


<p>在使用tf.summary的时候的坑主要是在使用tf.summary.merge_all()的时候，具体的错误和解决方法参见参考文献第二个。</p>
<p>第二个坑主要是训练模型的accuracy在不断提高，loss在不断减少，但是测试模型的数据却非常混乱。<br />
训练和测试模型的accuracy 和cost，Tensorboard中的GRAPHS如下<br />
<center><img src="/wiki/static/images/mnist/acc_cost.png" alt="GRAPHS_UNROLLING" height="600" width="600"/></center><br />
<center><img src="/wiki/static/images/mnist/tran_test_erro.png" alt="GRAPHS_UNROLLING" height="600" width="600"/></center></p>
<p>原先我开始怀疑是否是超参的设置问题，但是不管怎么调节其结果都没有什么变化，测试集的精度依旧很低，cost也没有变化。后面还调了网络结构，把该省的都省掉了，构造一个最简单的RNN网络，问题还是没有解决。很纠结。<br />
后来开始怀疑是共享变量的问题，将所有的变量都加上tf.variable_scope(),问题依然存在，没办法在一个技术群里把这个问题提了出来，估计大部分人都没想过这个问题，没人回答。我很尴尬，最后实在没办法去youtube上找教程，想从一些教程里面找到是否有人会像我这样把train和test分开，找到一个类似的，只不过是使用的cnn解决mnist问题。<br />
在他的技术讨论群里我把这个问题提出来后一个伙伴提醒我可能是tf.Variable()的原因，他在官网上把tf.Variable和tf.get_variable的区别发给我看了下，然后我把我的程序里面涉及到的tf.Variable改写成tf.get_variable，果然问题解决了，下面是改写前后的代码。</p>
<p>改写前</p>
<div class="hlcode"><pre><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">&quot;weight&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c"># (28, 128)</span>
        <span class="s">&#39;in&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_units</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s">&#39;in&#39;</span><span class="p">),</span>
        <span class="c"># (128, 10)</span>
        <span class="s">&#39;out&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_units</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s">&#39;out&#39;</span><span class="p">)</span>
    <span class="p">}</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">&quot;weight&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">&#39;in&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_units</span><span class="p">,</span> <span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s">&#39;in&#39;</span><span class="p">),</span>
        <span class="c"># (10, )</span>
        <span class="s">&#39;out&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s">&#39;out&#39;</span><span class="p">)</span>
    <span class="p">}</span>
</pre></div>


<p>改写后</p>
<div class="hlcode"><pre><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">&quot;weight&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c"># (28, 128)</span>
        <span class="s">&#39;in&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">&#39;in&#39;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_units</span><span class="p">])),</span>
        <span class="c"># (128, 10)</span>
        <span class="s">&#39;out&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">&#39;out&#39;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_units</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span><span class="p">]))</span>
    <span class="p">}</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">&quot;biases&quot;</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c"># (128, )</span>
        <span class="s">&#39;in&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">&#39;in&#39;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_units</span><span class="p">,</span> <span class="p">])),</span>
        <span class="c"># (10, )</span>
        <span class="s">&#39;out&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">&#39;out&#39;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="p">]))</span>
    <span class="p">}</span>
</pre></div>


<p>改写前后的GRAPHS发生了改变，model中多了这两个变量，说明之前虽然model共享了，但是里面的变量依然没有共享。</p>
<h2 id="_2">总结</h2>
<p>之前在看变量共享的文档时只是说tf.get_variable()对变量的复用和作用域会有影响，主要是很多源代码都是使用tf.Variable来定义变量的。官网上也明确说明最好使用tf.get_variable来定义变量。<br />
但其实这里面的精髓还没有领会，model这个类共享了，而里面的参数竟然没有共享，有点想不通，或者说我的代码依然不严谨。<br />
文献3中有提到变量的作用域机制，讲到通过tf.get_variable()所给的名字创建或是返回一个变量, 通过tf.variable_scope()为变量名指定命名空间。</p>
<h2 id="_3">参考文献</h2>
<p><a href="https://github.com/STHSF/DeepLearning/tree/master/TF/RNN">文中涉及到的完全代码</a><br />
<a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/使用Tensorflow爬过的坑/tensorflow.python.framework.errors_impl.InvalidArgumentError.html">tensorflow.python.framework.errors_impl.InvalidArgumentError</a><br />
<a href="https://www.cnblogs.com/rocketfan/p/5773373.html">Tensorflow 变量的共享</a></p>
</div>
<div id="content-footer">created in <span class="create-date date"> 2017-11-22 00:10 </span></div>
<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  title: '全面详解Tensorflow使用LSTM进行MNIST手写字符分类',
  owner: 'sthsf',
  repo: 'wiki',
  oauth: {
    client_id: '086c54c5fd95adfdc372',
    client_secret: '2ad9ebe87b952d2c77fccf99c334881b91eaa73d',
  },
  // ...
  // For more available options, check out the documentation below
})
gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

</div>
<div id="footer">
            <span>
                Copyright © 2019 LiYu.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
                Fork me in <a href="https://github.com/sthsf/wiki" target="_blank"> github </a>.
            </span>
</div>


<!--百度统计-->
<script>
    var _hmt = _hmt || [];
    (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?90e1dcdd1938573c19f9ff6521188e91";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>


</body>
</html>