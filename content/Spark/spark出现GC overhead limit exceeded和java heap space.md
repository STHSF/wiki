---
title: "Spark的性能调优---spark出现GC overhead limit exceeded和java heap space"
layout: page
date: 2018-03-24 00:00
---

# 写在前面



# 参考文献
[spark出现GC overhead limit exceeded和java heap space](http://cache.baiducontent.com/c?m=9d78d513d98203fc18b4837e7c4386711925dd276b978a422c828448e23a001e1c20f4bb56755a5584922a3057bb0e1cb4ff6c34714161a09abb95578de5cf7d38885065314ada5612a445f88d5b7a8a62d007aef948baeca76cc8fa85ce8c141591025b2d9da6dc1c534f942eed1234e2a29e491558&p=882a9644d7800aec17be9b7c424483&newp=9b70c64ad4934eac59ecde2c4e4dc1231610db2151d6d71e6b82c825d7331b001c3bbfb423251102d3c67a6300a54959ecf13077350523a3dda5c91d9fb4c57479&user=baidu&fm=sc&query=spark+GC+overhead+limit+exceeded&qid=c7ce7e550000e79c&p1=2)

[Spark的性能调优](http://www.raychase.net/3546)

[GC overhead limit exceeded : Spark](https://blog.csdn.net/glad_xiao/article/details/49095289)
[spark-OutOfMemory:GC overhead limit exceeded 解决](https://blog.csdn.net/amghost/article/details/45303315)